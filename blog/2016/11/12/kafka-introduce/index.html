<!DOCTYPE html>
<html lang="en-us">
  
  <head>
  <title>Kafka介绍 - 清园索道</title>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <meta name="author" content="Xuancong Lee" />
    <meta name="description" content="kafka介绍" />
    <meta name="keywords" content="kafka" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link rel="stylesheet" href="/media/css/main.css" type="text/css">
  <link rel="stylesheet" href="/media/css/base16-ocean.light-min.css" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Fira+Sans' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Fira+Mono' rel='stylesheet' type='text/css'>
</head>

  <body>
    <div id="page-wrap">
      <div>
  <header id="header">
    <div class="logo">
      <h1><a href="/"><span class="logo-black">清园索道</span></a></h1>
    </div>
    <div class="fortune">
      <blockquote>
        上下求索，识己识人识事
      </blockquote>
    </div>
    <ul id="main-nav">
        <li><a href="/blog/">Blog</a></li>
      <li><a href="/tags/">分类</a></li>
      <li><a href="/about/">关于我</a></li>
      <li><a href="https://github.com/congleetea">GitHub</a></li>
      <li><a href="/rss.xml">RSS</a></li>
    </ul>
  </header>
</div>

      <article id="content">
        
  <h1>Kafka介绍</h1>


<div id="outline-container-org4daa3fc" class="outline-2">
<h2 id="org4daa3fc">Kafka 的设计</h2>
<div class="outline-text-2" id="text-org4daa3fc">
<p>
设计的动机: 能够作为一个统一的可以处理一家大公司可能有的所有实时数据的平台。
</p>

<p>
要做到这一点，我们需要考虑一个相当广泛的使用场景：
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-left">它必须具有高吞吐量，以支持大容量的事件流，如实时日志聚合。</td>
</tr>

<tr>
<td class="org-right">2</td>
<td class="org-left">优雅地处理大量数据积压，要能够支持从离线系统(offline system)中定期数据装载。</td>
</tr>

<tr>
<td class="org-right">3</td>
<td class="org-left">该系统需要实现低延迟交付，以处理更传统的消息传递任务。</td>
</tr>
</tbody>
</table>

<p>
根据这些需求和目标，形成了 kafka 的分区模式和消费者模式， 同时加入了一些新的元素。因此，比起传统的消息系统，kafka 更像一个数据库日志。
</p>
</div>
</div>

<div id="outline-container-org236f8bd" class="outline-2">
<h2 id="org236f8bd">Topic和分区</h2>
<div class="outline-text-2" id="text-org236f8bd">
<ul class="org-ul">
<li>Topic是一类消息的集合，通常这些消息比较大，因此一个Topic会分成多个分区，数据按照某种规则送到各个分区上。</li>
<li>分区Partition相当与Topic的其中一个队列，到达同一个分区上的消息有一个偏移值，这个值会一次递增。</li>
<li>分区可以均衡各个broker之间的数据和请求压力；分摊处理不同消费者进程,使消费速度更快；每个Partition内可以保证严格的时序。</li>
<li>消息以顺序写磁盘的形式写入磁盘中，速度很快，甚至比随机写内存还快，这是kafka高吞吐的重要原因。</li>
<li>每个分区在磁盘中都是一个目录，目录下包含*.index, *.log, *.timeindex三类文件。*就是给文件第一条消息的offset。</li>
<li>由于具有持久化的功能，众多的数据不能放在一个文件中，因此每个分区的消息会分成块存成不同的文件，可以设置每个文件的大小，块文件大小到了就重新生成新的文件。</li>
<li>旧的数据可以被删除，可以配置成按照过期时间和数据大小删除。</li>
<li>创建Topic时，可以指定分成多少Partition，每个分区的复制因子是多少(不同复本在不同的broker上，因此复制因子不能超过broker个数)。</li>
<li>每个Topic的所有Partitions会分散在不同的broker上，如果是单个broker，那所有都分布在这一个broker上。</li>
<li>Partition所有副本集中有一个是leader，其他是follower。follower像消费者一样从leader上拉取数据作为备份。</li>
<li>Partition的复制因子为N，则可以容错N-1个broker挂掉而不丢失数据。</li>

<li>通常客户端无法控制是否新建topic，kafka查看其设置auto.create.topics.enable和num.partitions来自行处理是否新建topic以及topic的分区数目。</li>
</ul>
</div>
</div>

<div id="outline-container-org64a2b8f" class="outline-2">
<h2 id="org64a2b8f">生产者和消费者</h2>
<div class="outline-text-2" id="text-org64a2b8f">
<ul class="org-ul">
<li>生产者直接将消息发送分区的leader broker，不经过任何路由层，包括zookeeper。</li>
<li>生产者确定每条消息送给那个partition，方式有round-robin，也可以根据指定的key计算哈希值让相同key的消息发送固定的分区(这适合消费着对消息位置比较敏感的场合)。</li>
<li>为了方便producer做到上面的功能，所有的kafka brokers都会回复Producer对分区元数据的请求。Producer得到分区的元数据就知道直接将数据送给那个broker了。</li>
<li>可以选择数据批处理功能，这是kafka高性能的一个原因，这样kafka可以将数据放在内存中，等数据累积的大小或者时间足够大再一起打包发往kafka，这样可以大大的减小服务器的I/O操作。因此，需要再节省服务器IO操作和实时性之间做出选择。</li>
<li>生产者使用push方式主动向kafka推送数据，而消费者以Pull的方式根据自己的消费能力向broker拉取数据。</li>
</ul>
</div>
</div>

<div id="outline-container-orge11e814" class="outline-2">
<h2 id="orge11e814">Kafka可以扮演的三种角色</h2>
<div class="outline-text-2" id="text-orge11e814">
</div>
<div id="outline-container-org8c63ca0" class="outline-3">
<h3 id="org8c63ca0">Messaging System</h3>
<div class="outline-text-3" id="text-org8c63ca0">
<ul class="org-ul">
<li>传统的消息系统有两种模式：队列和Publish/Subscribe，前者多个消费者抢一个列队的消息，只能由一个消费者消费，消费完即删除；后者会将消息分发给所有需要消费该消息的消费者。前者属于单播，后者属于广播。</li>
<li>Kafka提出消费组的概念可以实现上面两类，一个消费组的消费者只能由一个能消费一条消息，属于单播，但和传统消息系统不一样的是消费完后消息不会被删除；如果每个消费者做一个组，那就都会消费每一条消息，属于广播。</li>
<li>传统消费者可以保证消息到服务器的时序，但是如果不同进程抢同一个队列的消息，处理的顺序就可能不一样，因此，传统的队列有一个"exclusive consumer"的概念，即排外的消费者，也就是只有一个进程去消费一个队列的消息，这样就保证了时序，kakfa由于是一个分区只能被一个consumer消费，所有同一个分区的消息在消费的时候也能保证严格的时序，但是多个分区的消息就不能保证时序了。</li>
</ul>
</div>
</div>

<div id="outline-container-org5a29099" class="outline-3">
<h3 id="org5a29099">Storage System</h3>
<div class="outline-text-3" id="text-org5a29099">
<ul class="org-ul">
<li>Kafka解耦了消息发布和消费，这样就像一个数据库一样，其实也是一个数据存储系统。</li>
<li>到Kafka的数据被写进磁盘，并有副本来容错。Kafka允许producer等待ack确认消息已经写到kafka并已经有一定数量的副本。</li>
<li>Kafka使用顺序写磁盘，复杂度一样O(1)，不管服务器保存50KB还是50TB，性能都一样。</li>
<li>可以追踪消费者消费分区数据的偏移，并可以手动修改偏移值，重新消费某个偏移值开始的数据。</li>
</ul>
</div>
</div>

<div id="outline-container-org5dba109" class="outline-3">
<h3 id="org5dba109">Stream Processing</h3>
<div class="outline-text-3" id="text-org5dba109">
<ul class="org-ul">
<li>仅仅读写存数据还不够，流处理还可以实时处理数据, 即从输入topic中提取连续的数据，处理之后放到另外一个topics。</li>
<li>这类运用可以使用producer和consumer来实现，也就是消费者消费topic-in的数据之后，处理之后产生新的数据送到topic-out中。</li>
<li>Kafka针对该功能有独立的API可以使用。</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org75fe53a" class="outline-2">
<h2 id="org75fe53a">配置</h2>
<div class="outline-text-2" id="text-org75fe53a">
</div>
<div id="outline-container-orgfff3a58" class="outline-3">
<h3 id="orgfff3a58">Kafka Broker的配置</h3>
</div>
<div id="outline-container-org0eb2af6" class="outline-3">
<h3 id="org0eb2af6">Producer 和 Consumer 的配置</h3>
</div>
</div>

<div id="outline-container-org662ae05" class="outline-2">
<h2 id="org662ae05">消息的保证</h2>
<div class="outline-text-2" id="text-org662ae05">
<ul class="org-ul">
<li>和mqtt一样，消息有三种保证：最多投递一次(可能丢失，不会重新投递)；至少投递一次（不会丢失，且有可能重复）；有且仅有一次(不会丢失且只有一次).</li>
<li>Publish的消息有committed的概念，committed的消息是只要复制该分区的broker有一个alive(broker alive的定义在后面)，这条消息就不会被丢失, 也可以说是这些消息已经到达了所有的ISR。</li>
<li>虽然定义的committed消息是所有ISR都复制了这条消息，但是考虑实时性等性能问题，producer往往设置只要收到几个ISR的ack就算这条消息已经圆满到达了。默认是ack=all。</li>
<li>想想一种场景：消息发往kafka时发生网络问题；消息committed之后发生网络问题。这样都不确定是否执行成功。</li>
<li>消息保证通用的逻辑是：要确保这个需要接收者给发送这一个确认信息。qos=1的逻辑是发送者暂时保留消息如果一定时间内没有收到接收者确认信息就重发; qos=2的逻辑是发送者收到接受者将消息投递给下一级用户之后的回复再删除。</li>
<li>[对于Producer]：这种保证带来了很大的延时和性能问题，不是特别严格的场合不需要使用。因此需要producer指定是否需要这种保证，和等待确认的时间。</li>
<li>[对于Consumer]：消费者有消费的偏移值，消费者正常时将这个值保存内存中，消费者挂了后，如果另起一个进程消费该如何确定消费的偏移？该怎么做呢？有一下选择：</li>
<li>选择1：消费者读取数据之后，将消费的offset保存在log里再处理数据，后面启动的进程读取该log，接着上次消费的数据消费，这是at-most-once清醒，因为没有处理就已经把offset保存到log了，如果消息处理失败就不会重复消费这条消息了。所有启动Kafka的时候我们会看到自动创建的topic：__consumer_offsets。</li>
<li>选择2：消费者读取数据之后，处理完数据之后再将将消费的offset保存在log，这样确保保存offset的消息一定是被处理过的。</li>
<li>qos=2的情况，kafka还没有实现。</li>
<li>消息的offset，之前保存在zookeeper中，现在建议保存在kafka中。java的consumer API可以设置offsets.storage指定。</li>
</ul>
</div>
</div>

<div id="outline-container-orgd2f270c" class="outline-2">
<h2 id="orgd2f270c">分区的broker角色和副本</h2>
<div class="outline-text-2" id="text-orgd2f270c">
<ul class="org-ul">
<li>分区的副本因此在创建topic的时候指定。</li>
<li>保存同一分区的broker集合有不同的角色，leader，replicas和isr。</li>
<li>leader是分区负责读写的broker，每个broker都可能是某些分区的leader，也可能是某些分区的副本broker。</li>
<li>replicas是复制该分区数据的所有broker，不管这个broker是否alive，也包括这个分区的leader。</li>
<li>isr(in-sync)是当前活着并且数据跟上leader的所有节点。复制的数据是否跟上leader。</li>
<li>alive broker要满足两个条件：broker必须和zookeeper建立session，进而实现心跳机制；如果是slave，复制leader的数据不能差的太远，通过replica.lag.time.max.ms配置。满足这两个条件的就是in-snyc的node(ISR)，这样区别alive/failed的模糊概念。</li>
<li>leader会跟踪Partition的ISR集合，如果ISR里面某个挂了，或者数据复制落后太多，leader会将其从ISR列表中删除。</li>
<li>配置brokers优雅关闭，一个broker fail之后需要选出以该broker作为leader的分区的新leader，优雅的关闭有这些好处：同步所有数据到disk，避免重启之后进行任何log恢复，log恢复会花费很长的时间，所以同步数据可以使重启更块；关闭之前会迁移作为leader的分区的数据到其他replicas，这样能加快新的leader转移, 减小分区不可用的时间到几ms。前者会再服务给stop（不是强制关闭）前自动执行，后者由controlled.shutdown.enable=true(默认就是true)设置。</li>
<li>有一个preferred replicas（优先副本）的概念, ISR里的第一个就是优先副本。一个服务器挂了，新的leader会选出来，挂了的服务器恢复之后也只能做follower，不能进行读写了，这样会造成imbalance，可以通过执行下面的脚本重新恢复preferred replicas:
bin/kafka-preferred-replica-election.sh --zookeeper zk_host:port/chroot
执行上述指令很麻烦，可以设置服务器参数auto.leader.rebalance.enable=true实现自动平衡。</li>
</ul>
</div>
</div>

<div id="outline-container-org1e52086" class="outline-2">
<h2 id="org1e52086">权限控制</h2>
<div class="outline-text-2" id="text-org1e52086">
</div>
<div id="outline-container-org1fe7d37" class="outline-3">
<h3 id="org1fe7d37">使用SASL认证</h3>
<div class="outline-text-3" id="text-org1fe7d37">
<p>
有以下步骤：
</p>
</div>

<div id="outline-container-orgc94306c" class="outline-4">
<h4 id="orgc94306c">配置zk集群</h4>
<div class="outline-text-4" id="text-orgc94306c">
<p>
zk集群可以不配置auth。
</p>
</div>
</div>
</div>

<div id="outline-container-org6729ea3" class="outline-3">
<h3 id="org6729ea3">配置kafka服务器</h3>
<div class="outline-text-3" id="text-org6729ea3">
<ul class="org-ul">
<li>vim config/kafka_server_jaas.conf</li>
</ul>

<div class="org-src-container">
<pre class="src src-text">KafkaServer {
org.apache.kafka.common.security.plain.PlainLoginModule required # 指定认证的插件。
username="admin"
password="admin"
user_admin="admin"
user_manager="manager"
user_producer="producer"
user_consumer="consumer";
};
</pre>
</div>

<ul class="org-ul">
<li>修改kafka配置文件config/server.properties</li>
</ul>

<div class="org-src-container">
<pre class="src src-text"># 指定acl的插件。
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
listeners=SASL_PLAINTEXT://192.168.1.100:9092
security.inter.broker.protocol= SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=PLAIN
sasl.enabled.mechanisms=PLAIN
super.users=User:admin
allow.everyone.if.no.acl.found=false
</pre>
</div>

<ul class="org-ul">
<li>修改kafka-server-start.sh最后一行, 加上auth的jaas文件</li>
</ul>

<div class="org-src-container">
<pre class="src src-shell">exec $base_dir/kafka-run-class.sh $EXTRA_ARGS -Djava.security.auth.login.config=$base_dir/../config/kafka_server_jaas.conf kafka.Kafka "$@"
</pre>
</div>

<ul class="org-ul">
<li>启动zk</li>
</ul>
<div class="org-src-container">
<pre class="src src-shell">./bin/zkServer.sh start
</pre>
</div>

<ul class="org-ul">
<li>启动kafka</li>
</ul>

<div class="org-src-container">
<pre class="src src-shell">./bin/kafka-server-start.sh ./config/server.properties
</pre>
</div>

<ul class="org-ul">
<li>acl:</li>
</ul>

<div class="org-src-container">
<pre class="src src-shell">./bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181  --add --allow-principal User:lixuancong1  --operation Read 
--topic device_data_bd601ae2abdcd8c6bd4d22970629830b --group intoyun-data-group
./bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181  --add --allow-principal User:lixuancong1  --operation Read 
--topic device_data_default --group intoyun-data-group
</pre>
</div>

<ul class="org-ul">
<li>使用elb负载均衡访问</li>
</ul>

<p>
<a href="https://stackoverflow.com/questions/38666795/does-kafka-support-elb-in-front-of-broker-cluster">https://stackoverflow.com/questions/38666795/does-kafka-support-elb-in-front-of-broker-cluster</a>
</p>

<p>
使用elb的时候，也要确保各个kafka server能被client访问，因为client首先从elb上获取topic和分区的metadata，包括分区的leader server，后面就直接访问
该服务器。所以必须要把通过advertised把外网放出去。
</p>

<div class="org-src-container">
<pre class="src src-text"># 指定acl的插件。
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
listeners=SASL_PLAINTEXT://0.0.0.0:9092
advertised.listeners=SASL_PLAINTEXT://外网IP:9092
security.inter.broker.protocol= SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=PLAIN
sasl.enabled.mechanisms=PLAIN
super.users=User:admin
allow.everyone.if.no.acl.found=false
</pre>
</div>



<ul class="org-ul">
<li>安装mvn编译工具：</li>
</ul>
<p>
<a href="http://blinkfox.com/linux-debianxia-mavende-an-zhuang-he-shi-yong/">http://blinkfox.com/linux-debianxia-mavende-an-zhuang-he-shi-yong/</a>
</p>

<ol class="org-ol">
<li>wget <a href="http://mirror.nus.edu.sg/apache/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.tar.gz">http://mirror.nus.edu.sg/apache/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.tar.gz</a></li>

<li>sudo mkdir /usr/lib/maven</li>

<li>sudo tar -zxf apache-maven-3.5.0-bin.tar.gz -C /usr/lib/maven</li>

<li>.zshrc文件添加：</li>
</ol>

<div class="org-src-container">
<pre class="src src-shell">export M2_HOME=/usr/lib/maven/apache-maven-3.5.0  
export M2=$M2_HOME/bin  
export PATH=$M2:$PATH   
</pre>
</div>

<ol class="org-ol">
<li>source ~/.zshrc</li>

<li>测试是否安装成功: mvn -version</li>
</ol>

<div class="org-src-container">
<pre class="src src-text">Apache Maven 3.5.0 (ff8f5e7444045639af65f6095c62210b5713f426; 2017-04-04T03:39:06+08:00)
Maven home: /usr/lib/maven/apache-maven-3.5.0
Java version: 1.8.0_131, vendor: Oracle Corporation
Java home: /usr/local/jdk1.8.0_131/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.4.0-85-generic", arch: "amd64", family: "unix"
</pre>
</div>

<p>
LoginModule的initialize这个方法的目的就是用有关的信息去实例化这个LoginModule。如果login成功，
在这个方法里的Subject就被用在存储Principals和Credentials.  注意这个方法有一个能被用作输入认证
信息的CallbackHandler。在这个例子里，我没有用CallbackHandler. CallbackHandler是有用的，因为它
从被用作特定输入设备里分离了服务提供者。
</p>

<p>
SASL:
</p>
<ol class="org-ol">
<li>创建服务端机制(客户端其实也需要，但再kafka中我们需要的是服务机制)</li>
</ol>

<p>
public SaslServer createSaslServer(String mechanism, String protocol, String serverName, Map&lt;String, ?&gt; props, CallbackHandler cbh)
</p>

<ol class="org-ol">
<li>ACLs</li>
</ol>

<p>
list:
</p>

<div class="org-src-container">
<pre class="src src-shell">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --list --topic 
</pre>
</div>

<p>
add:
</p>

<div class="org-src-container">
<pre class="src src-shell">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic Test-topic
</pre>
</div>


<p>
remove:
</p>

<div class="org-src-container">
<pre class="src src-shell">bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --remove --allow-principal User:Bob --allow-principal User:Alice --allow-host 198.51.100.0 --allow-host 198.51.100.1 --operation Read --operation Write --topic Test-topic
</pre>
</div>
</div>
</div>
</div>


      </article>
      <div>
    <ul id="tags">
        <li><a href="/tags/services/">services</a></li>
    </ul>
    <div class="post-meta">
      <span title="post date">Published: 2016-11-12</span>
      </br>
      <span title="last modification date">Last Modification: 2020-08-14</span>
      </br>
      <span title="author" >Author: Xuancong Lee</span>
    </div>
    <section>
      <h2>Comments</h2>
        <div id="disqus_thread"></div>
        <script type="text/javascript">
        //var disqus_developer = 1;
        var disqus_identifier = "/blog/2016/11/12/kafka-introduce";
        var disqus_url = "https://congleetea.github.io/blog/2016/11/12/kafka-introduce";
        var disqus_shortname = 'congleetea';
        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="//disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </section>
  <script src="//code.jquery.com/jquery-latest.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/highlight.min.js"></script>
  <script src="/media/js/main.js"></script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <div class="copyright">
    <p>Generated by <a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.x (<a href="http://orgmode.org">Org mode</a> 9.x)</p>
    <p>
      Copyright &copy; 2012 - <span id="footerYear"></span> <a href="mailto:congleetea &lt;at&gt; gmail &lt;dot&gt; com">Xuancong Lee</a>
      &nbsp;&nbsp;-&nbsp;&nbsp;
      Powered by <a href="https://github.com/kelvinh/org-page" target="_blank">org-page</a>
      <script type="text/javascript">document.getElementById("footerYear").innerHTML = (new Date()).getFullYear();</script>
    </p>
  </div>
</div>

    </div>
  </body>
</html>
